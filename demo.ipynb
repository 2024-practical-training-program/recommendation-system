{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barrywu/anaconda3/envs/tools/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为用户 U001 推荐的商品：\n",
      "1. 智能手表\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 加载中文RoBERTa模型和Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "model = AutoModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\", output_hidden_states=True)\n",
    "\n",
    "def encode_text(text):\n",
    "    \"\"\"\n",
    "    使用中文RoBERTa模型将商品描述转化为向量表示。\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    # 获取最后一层隐藏状态的平均值\n",
    "    hidden_states = outputs.hidden_states\n",
    "    last_layer_hidden_state = hidden_states[-1]  # 最后一层的隐藏状态\n",
    "    return last_layer_hidden_state.mean(dim=1).detach().numpy().squeeze()\n",
    "\n",
    "# 2. 模拟用户行为数据\n",
    "user_behavior_data = [\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1001\", \"action\": \"浏览\", \"item_description\": \"时尚蓝牙耳机\", \"timestamp\": \"2025-01-01 10:00\"},\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1002\", \"action\": \"浏览\", \"item_description\": \"智能手表\", \"timestamp\": \"2025-01-01 10:15\"},\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1003\", \"action\": \"加入购物车\", \"item_description\": \"4K电视\", \"timestamp\": \"2025-01-01 10:30\"},\n",
    "    {\"user_id\": \"U002\", \"item_id\": \"P1002\", \"action\": \"浏览\", \"item_description\": \"智能手表\", \"timestamp\": \"2025-01-01 11:00\"},\n",
    "    {\"user_id\": \"U003\", \"item_id\": \"P1001\", \"action\": \"购买\", \"item_description\": \"时尚蓝牙耳机\", \"timestamp\": \"2025-01-01 11:30\"},\n",
    "    {\"user_id\": \"U002\", \"item_id\": \"P1003\", \"action\": \"购买\", \"item_description\": \"4K电视\", \"timestamp\": \"2025-01-01 12:00\"},\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1001\", \"action\": \"浏览\", \"item_description\": \"时尚蓝牙耳机\", \"timestamp\": \"2025-01-01 12:30\"},\n",
    "]\n",
    "\n",
    "# 3. 构建用户行为向量\n",
    "def build_user_vector(user_id, user_behavior_data):\n",
    "    \"\"\"\n",
    "    根据用户的行为记录生成一个兴趣向量。\n",
    "    \"\"\"\n",
    "    user_history = [entry[\"item_description\"] for entry in user_behavior_data if entry[\"user_id\"] == user_id]\n",
    "    if not user_history:\n",
    "        return np.zeros(768)  # 中文RoBERTa模型输出的向量维度为768\n",
    "    # 计算用户历史行为的平均向量\n",
    "    user_vectors = np.mean([encode_text(desc) for desc in user_history], axis=0)\n",
    "    return user_vectors\n",
    "\n",
    "# 4. 示例商品描述\n",
    "item_descriptions = [\n",
    "    \"airpods\",\n",
    "    \"智能手表\",\n",
    "    \"4K电视\",\n",
    "    \"无线耳机\",\n",
    "    \"超高清电视\"\n",
    "]\n",
    "\n",
    "# 5. 将商品描述转化为向量\n",
    "item_vectors = np.array([encode_text(desc) for desc in item_descriptions])\n",
    "\n",
    "# 6. 推荐系统\n",
    "def recommend(user_id, user_behavior_data, item_descriptions, item_vectors, top_n=3, similarity_threshold=0.5):\n",
    "    \"\"\"\n",
    "    为指定用户推荐商品，支持设置推荐数量和相似度阈值。\n",
    "    \"\"\"\n",
    "    # 获取用户兴趣向量\n",
    "    user_vector = build_user_vector(user_id, user_behavior_data)\n",
    "    \n",
    "    # 计算用户兴趣向量与商品向量的相似度\n",
    "    similarities = cosine_similarity([user_vector], item_vectors)\n",
    "    \n",
    "    # 过滤掉低于相似度阈值的商品\n",
    "    filtered_items = [idx for idx, sim in enumerate(similarities[0]) if sim >= similarity_threshold]\n",
    "    \n",
    "    if not filtered_items:\n",
    "        print(\"没有符合条件的商品推荐！\")\n",
    "        return []\n",
    "    \n",
    "    # 根据相似度排序，推荐最相关的商品\n",
    "    recommended_items = np.argsort(similarities[0][filtered_items])[::-1]\n",
    "    \n",
    "    # 返回推荐的商品（限制数量为top_n）\n",
    "    recommended_item_ids = [item_descriptions[filtered_items[i]] for i in recommended_items[:top_n]]\n",
    "    return recommended_item_ids\n",
    "\n",
    "# 7. 为用户U001推荐商品\n",
    "user_id = \"U001\"\n",
    "recommended_items = recommend(user_id, user_behavior_data, item_descriptions, item_vectors, top_n=1, similarity_threshold=0.5)\n",
    "\n",
    "# 输出推荐结果\n",
    "print(f\"为用户 {user_id} 推荐的商品：\")\n",
    "for idx, item in enumerate(recommended_items):\n",
    "    print(f\"{idx + 1}. {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaf98cd8979432b87c61487e322f880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为用户 U001 推荐的商品：\n",
      "1. 智能手表\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 加载Qwen2.5-3B模型和Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B\")\n",
    "model = AutoModel.from_pretrained(\"Qwen/Qwen2.5-3B\", output_hidden_states=True)\n",
    "\n",
    "def encode_text(text):\n",
    "    \"\"\"\n",
    "    使用Qwen2.5-3B模型将商品描述转化为向量表示。\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    # 获取最后一层隐藏状态的平均值\n",
    "    hidden_states = outputs.hidden_states\n",
    "    last_layer_hidden_state = hidden_states[-1]  # 最后一层的隐藏状态\n",
    "    return last_layer_hidden_state.mean(dim=1).detach().numpy().squeeze()\n",
    "\n",
    "# 2. 模拟用户行为数据\n",
    "user_behavior_data = [\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1001\", \"action\": \"浏览\", \"item_description\": \"时尚蓝牙耳机\", \"timestamp\": \"2025-01-01 10:00\"},\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1002\", \"action\": \"浏览\", \"item_description\": \"智能手表\", \"timestamp\": \"2025-01-01 10:15\"},\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1003\", \"action\": \"加入购物车\", \"item_description\": \"4K电视\", \"timestamp\": \"2025-01-01 10:30\"},\n",
    "    {\"user_id\": \"U002\", \"item_id\": \"P1002\", \"action\": \"浏览\", \"item_description\": \"智能手表\", \"timestamp\": \"2025-01-01 11:00\"},\n",
    "    {\"user_id\": \"U003\", \"item_id\": \"P1001\", \"action\": \"购买\", \"item_description\": \"时尚蓝牙耳机\", \"timestamp\": \"2025-01-01 11:30\"},\n",
    "    {\"user_id\": \"U002\", \"item_id\": \"P1003\", \"action\": \"购买\", \"item_description\": \"4K电视\", \"timestamp\": \"2025-01-01 12:00\"},\n",
    "    {\"user_id\": \"U001\", \"item_id\": \"P1001\", \"action\": \"浏览\", \"item_description\": \"时尚蓝牙耳机\", \"timestamp\": \"2025-01-01 12:30\"},\n",
    "]\n",
    "\n",
    "# 3. 构建用户行为向量\n",
    "def build_user_vector(user_id, user_behavior_data):\n",
    "    \"\"\"\n",
    "    根据用户的行为记录生成一个兴趣向量。\n",
    "    \"\"\"\n",
    "    user_history = [entry[\"item_description\"] for entry in user_behavior_data if entry[\"user_id\"] == user_id]\n",
    "    if not user_history:\n",
    "        return np.zeros(768)  # 假设Qwen2.5-3B模型输出的向量维度为768\n",
    "    # 计算用户历史行为的平均向量\n",
    "    user_vectors = np.mean([encode_text(desc) for desc in user_history], axis=0)\n",
    "    return user_vectors\n",
    "\n",
    "# 4. 示例商品描述\n",
    "item_descriptions = [\n",
    "    \"headset\",\n",
    "    \"智能手表\",\n",
    "    \"4K电视\",\n",
    "    \"无线耳机\",\n",
    "    \"超高清电视\"\n",
    "]\n",
    "\n",
    "# 5. 将商品描述转化为向量\n",
    "item_vectors = np.array([encode_text(desc) for desc in item_descriptions])\n",
    "\n",
    "# 6. 推荐系统\n",
    "def recommend(user_id, user_behavior_data, item_descriptions, item_vectors, top_n=3, similarity_threshold=0.5):\n",
    "    \"\"\"\n",
    "    为指定用户推荐商品，支持设置推荐数量和相似度阈值。\n",
    "    \"\"\"\n",
    "    # 获取用户兴趣向量\n",
    "    user_vector = build_user_vector(user_id, user_behavior_data)\n",
    "    \n",
    "    # 计算用户兴趣向量与商品向量的相似度\n",
    "    similarities = cosine_similarity([user_vector], item_vectors)\n",
    "    \n",
    "    # 过滤掉低于相似度阈值的商品\n",
    "    filtered_items = [idx for idx, sim in enumerate(similarities[0]) if sim >= similarity_threshold]\n",
    "    \n",
    "    if not filtered_items:\n",
    "        print(\"没有符合条件的商品推荐！\")\n",
    "        return []\n",
    "    \n",
    "    # 根据相似度排序，推荐最相关的商品\n",
    "    recommended_items = np.argsort(similarities[0][filtered_items])[::-1]\n",
    "    \n",
    "    # 返回推荐的商品（限制数量为top_n）\n",
    "    recommended_item_ids = [item_descriptions[filtered_items[i]] for i in recommended_items[:top_n]]\n",
    "    return recommended_item_ids\n",
    "\n",
    "# 7. 为用户U001推荐商品\n",
    "user_id = \"U001\"\n",
    "recommended_items = recommend(user_id, user_behavior_data, item_descriptions, item_vectors, top_n=1, similarity_threshold=0.5)\n",
    "\n",
    "# 输出推荐结果\n",
    "print(f\"为用户 {user_id} 推荐的商品：\")\n",
    "for idx, item in enumerate(recommended_items):\n",
    "    print(f\"{idx + 1}. {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barrywu/anaconda3/envs/tools/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/barrywu/anaconda3/envs/tools/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/barrywu/anaconda3/envs/tools/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "公主和王子的余弦相似度：0.8404\n",
      "公主和青蛙的余弦相似度：0.7107\n",
      "公主和苹果的余弦相似度：0.5628\n",
      "公主和香蕉的余弦相似度：0.6400\n",
      "公主和牛马的余弦相似度：0.6865\n",
      "公主和猴子的余弦相似度：0.6656\n",
      "公主和国王的余弦相似度：0.7919\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 加载中文RoBERTa模型和Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "model = AutoModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "\n",
    "def encode_text(text):\n",
    "    \"\"\"\n",
    "    使用RoBERTa模型将文本转化为向量表示。\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # 获取最后一层隐藏状态的平均值作为文本的向量表示\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    sentence_embedding = torch.mean(last_hidden_state, dim=1).detach().numpy().squeeze()\n",
    "    return sentence_embedding\n",
    "\n",
    "# 词语列表\n",
    "words = [\"公主\", \"王子\", \"青蛙\", \"苹果\", \"香蕉\",\"牛马\",\"猴子\",\"国王\"]\n",
    "\n",
    "# 获取每个词语的向量表示\n",
    "word_vectors = np.array([encode_text(word) for word in words])\n",
    "\n",
    "# 计算“公主”与其他词语的余弦相似度\n",
    "princess_vector = word_vectors[0]  # \"公主\"的向量\n",
    "similarities = cosine_similarity([princess_vector], word_vectors[1:])\n",
    "\n",
    "# 输出每个词语的相似度\n",
    "for idx, word in enumerate(words[1:]):\n",
    "    print(f\"公主和{word}的余弦相似度：{similarities[0][idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'class': 'LangChain_78085c2ecb764d0393f50db51561c6bc', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_4a74a6848f724a05b0aac1dc75e3a67e', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Fri Dec 27 01:29:56 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_5a4e3b8d064b4371b1180140c218be53', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_519964f25eab4334b566d91350d337b3', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_f68a880e7a22428aac5d054ed9594587', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_be6fd16d1f0a4b9a85a19fc3cdf9cfbe', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_6c5d2c4015544e0488df08760e208d28', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_b558873a4b9d481c9b5c9672532a2835', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_11acbac9161c4d56a58b04106b7eac61', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 07:39:24 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 07:39:24 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_53aac4e08edc47dfbd951b93c0fe86ba', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 07:52:21 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 07:52:21 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_27a679a801a04cd5833ff12e24fbff28', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:31:38 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:31:38 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_49f8184e43cd4b89820f4db2e1c37466', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:32:58 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:32:58 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_2b58fac24dcb4c1e98dfefd215339449', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:36:54 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:36:54 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_098b86526de8408d8b5bd408d4d2f323', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:37:31 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:37:31 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_750114f3cb2840fb8bf30e1d9ab0e1f7', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:41:56 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:41:56 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_1fba54a30cf242fc98e5e1fa110c86d9', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:55:30 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 08:55:30 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_78465685a1754932b657f5b03af65d24', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:15:01 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:15:01 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_cc5e1eeaba7e442f9e2b864be1a03e52', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:16:14 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:16:14 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_bc03cfd395d6437fb67ab504a3a22a96', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:17:21 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:17:21 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_c6decb795e394c5f8acc76f22184b927', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:18:52 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:18:52 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_593369e0333c4399897549167f7a8506', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:21:05 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:21:05 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_d926f3f0644f4e96852335bad4b565a6', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:22:49 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:22:49 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_a9c0170e64ad45d5a271492eb2dde86c', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:23:56 2024\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 30 09:23:56 2024\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_f41e8b9939a64ffe94beec887dff0fb1', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_279fae52ee3f411580e743d74e7234b1', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Thu Jan  2 06:54:15 2025\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Thu Jan  2 06:54:15 2025\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_c2244d8548574460a17b0bb7fc5eb0bd', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Thu Jan  2 06:54:30 2025\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Thu Jan  2 06:54:30 2025\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_54a68ded2cbb4d1986bd9f29d7004a31', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jan  3 02:24:13 2025\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jan  3 02:24:13 2025\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'AcademicPaper', 'description': '学术论文和期刊', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'title', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'abstract', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'authors', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'journal', 'tokenization': 'word'}, {'dataType': ['text[]'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'keywords', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'doi', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'url', 'tokenization': 'word'}, {'dataType': ['int'], 'indexFilterable': True, 'indexSearchable': False, 'name': 'citations'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['date'], 'indexFilterable': True, 'indexSearchable': False, 'name': 'publishDate'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'News', 'description': '新闻和报道', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'title', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'content', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'summary', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'url', 'tokenization': 'word'}, {'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'mediaUrl', 'tokenization': 'word'}, {'dataType': ['date'], 'indexFilterable': True, 'indexSearchable': False, 'name': 'publishDate'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}, {'class': 'LangChain_e4fb67d801ea4e8eab81758db978fa69', 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2}, 'cleanupIntervalSeconds': 60, 'stopwords': {'additions': None, 'preset': 'en', 'removals': None}}, 'multiTenancyConfig': {'enabled': False}, 'properties': [{'dataType': ['text'], 'indexFilterable': True, 'indexSearchable': True, 'name': 'text', 'tokenization': 'word'}, {'dataType': ['text'], 'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jan  3 10:25:48 2025\", 'indexFilterable': True, 'indexSearchable': True, 'name': 'source', 'tokenization': 'word'}, {'dataType': ['number'], 'description': \"This property was generated by Weaviate's auto-schema feature on Fri Jan  3 10:25:48 2025\", 'indexFilterable': True, 'indexSearchable': False, 'name': 'chunk_index'}], 'replicationConfig': {'factor': 1}, 'shardingConfig': {'virtualPerPhysical': 128, 'desiredCount': 1, 'actualCount': 1, 'desiredVirtualCount': 128, 'actualVirtualCount': 128, 'key': '_id', 'strategy': 'hash', 'function': 'murmur3'}, 'vectorIndexConfig': {'skip': False, 'cleanupIntervalSeconds': 300, 'maxConnections': 64, 'efConstruction': 128, 'ef': -1, 'dynamicEfMin': 100, 'dynamicEfMax': 500, 'dynamicEfFactor': 8, 'vectorCacheMaxObjects': 1000000000000, 'flatSearchCutoff': 40000, 'distance': 'cosine', 'pq': {'enabled': False, 'bitCompression': False, 'segments': 0, 'centroids': 256, 'trainingLimit': 100000, 'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}, 'bq': {'enabled': False}}, 'vectorIndexType': 'hnsw', 'vectorizer': 'none'}]}\n"
     ]
    }
   ],
   "source": [
    "# 连接weaviate\n",
    "WEAVIATE_HOST = '124.222.113.16'\n",
    "WEAVIATE_PORT = '8080'\n",
    "WEAVIATE_URL = f'http://{WEAVIATE_HOST}:{WEAVIATE_PORT}'\n",
    "import weaviate\n",
    "# 创建Weaviate客户端\n",
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL,\n",
    ")\n",
    "# 获取模式\n",
    "schema = client.schema.get()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing weibo_data...\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '1' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '2' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '3' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '4' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '5' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '6' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '7' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '8' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '9' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '10' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '11' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '12' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '13' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '14' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '15' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '16' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '17' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '18' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '19' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '20' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '21' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '22' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '23' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '24' for key 'weibo_data.PRIMARY'\")\n",
      "Error inserting weibo data: (1062, \"Duplicate entry '25' for key 'weibo_data.PRIMARY'\")\n",
      "Successfully inserted weibo_data data\n",
      "Processing news_results...\n",
      "Successfully inserted news_results data\n",
      "Processing douban_topics...\n",
      "Successfully inserted douban_topics data\n",
      "Processing conferences...\n",
      "Successfully inserted conferences data\n",
      "Processing white_papers...\n",
      "Successfully inserted white_papers data\n",
      "Processing academic_papers...\n",
      "Successfully inserted academic_papers data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# 数据库连接配置\n",
    "DB_CONFIG = {\n",
    "    'host': '124.222.113.16',\n",
    "    'port': 3306,\n",
    "    'user': 'root',\n",
    "    'password': 'WYX&wyx',\n",
    "    'database': 'Zhihuiyuyan',\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    \"\"\"加载JSON文件\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def create_db_connection():\n",
    "    \"\"\"创建数据库连接\"\"\"\n",
    "    return pymysql.connect(**DB_CONFIG)\n",
    "\n",
    "def insert_weibo_data(conn, data):\n",
    "    \"\"\"插入微博数据\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"\"\"INSERT INTO weibo_data (id, author, publish_date, content, platform) \n",
    "             VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    for item in data:\n",
    "        try:\n",
    "            cursor.execute(sql, (\n",
    "                item['id'],\n",
    "                item['author'],\n",
    "                item['publish_date'],\n",
    "                item['content'],\n",
    "                item['platform']\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting weibo data: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "def parse_datetime(date_str):\n",
    "    \"\"\"解析各种格式的日期时间字符串\"\"\"\n",
    "    if not date_str or date_str == 'Unknown':\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # 尝试不同的日期格式\n",
    "        formats = [\n",
    "            '%Y-%m-%d %H:%M:%S',\n",
    "            '%Y-%m-%d %H:%M',\n",
    "            '%Y-%m-%d',\n",
    "            '%Y年%m月%d日 %H:%M',\n",
    "            '%Y年%m月%d日',\n",
    "            '%m月%d日 %H:%M',\n",
    "            '%H:%M:%S',\n",
    "            '%H:%M'\n",
    "        ]\n",
    "        \n",
    "        for fmt in formats:\n",
    "            try:\n",
    "                # 如果是没有年份的格式，添加当前年份\n",
    "                if '年' not in date_str and '-' not in date_str:\n",
    "                    date_str = f'2024年{date_str}'\n",
    "                return datetime.strptime(date_str, fmt)\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def insert_news_results(conn, data):\n",
    "    \"\"\"插入新闻数据\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"\"\"INSERT INTO news_results (id, title, content, summary, publish_date, \n",
    "             source, url, media_url) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    for item in data:\n",
    "        try:\n",
    "            # 解析日期\n",
    "            publish_date = parse_datetime(item['publish_date'])\n",
    "            \n",
    "            cursor.execute(sql, (\n",
    "                item['id'],\n",
    "                item['title'],\n",
    "                item['content'],\n",
    "                item['summary'],\n",
    "                publish_date,\n",
    "                item['source'],\n",
    "                item['url'],\n",
    "                item['media_url']\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting news data: {e}\")\n",
    "            print(f\"Problematic record: {item}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "def insert_douban_topics(conn, data):\n",
    "    \"\"\"插入豆瓣话题数据\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"\"\"INSERT INTO douban_topics (id, content, author, publish_date, \n",
    "             platform, url) VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    for item in data:\n",
    "        try:\n",
    "            # 解析日期\n",
    "            publish_date = parse_datetime(item['publish_date'])\n",
    "            \n",
    "            cursor.execute(sql, (\n",
    "                item['id'],\n",
    "                item['content'],\n",
    "                item['author'],\n",
    "                publish_date,\n",
    "                item['platform'],\n",
    "                item['url']\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting douban data: {e}\")\n",
    "            print(f\"Problematic record: {item}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "def insert_conferences(conn, data):\n",
    "    \"\"\"插入会议数据\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"\"\"INSERT INTO conferences (id, name, date, location, agenda, url, abstract) \n",
    "             VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    for item in data:\n",
    "        try:\n",
    "            cursor.execute(sql, (\n",
    "                item['id'],\n",
    "                item['name'],\n",
    "                item['date'],\n",
    "                item['location'],\n",
    "                json.dumps(item['agenda'], ensure_ascii=False),\n",
    "                item['url'],\n",
    "                item['abstract']\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting conference data: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "def insert_white_papers(conn, data):\n",
    "    \"\"\"插入白皮书数据\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"\"\"INSERT INTO white_papers (id, title, abstract, content, publish_date, \n",
    "             publisher, url) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    for item in data:\n",
    "        try:\n",
    "            cursor.execute(sql, (\n",
    "                item['id'],\n",
    "                item['title'],\n",
    "                item['abstract'],\n",
    "                item['content'],\n",
    "                item['publish_date'],\n",
    "                item['publisher'],\n",
    "                item['url']\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting white paper data: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "def insert_academic_papers(conn, data):\n",
    "    \"\"\"插入学术论文数据\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"\"\"INSERT INTO academic_papers (id, title, abstract, authors, publish_date, \n",
    "             journal, keywords, doi, url, citations) \n",
    "             VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    for item in data:\n",
    "        try:\n",
    "            cursor.execute(sql, (\n",
    "                item['id'],\n",
    "                item['title'],\n",
    "                item['abstract'],\n",
    "                json.dumps(item['authors'], ensure_ascii=False),\n",
    "                item['publish_date'],\n",
    "                item['journal'],\n",
    "                json.dumps(item.get('keywords', []), ensure_ascii=False),\n",
    "                item['doi'],\n",
    "                item['url'],\n",
    "                item['citations']\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting academic paper data: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    try:\n",
    "        # 创建数据库连接\n",
    "        conn = create_db_connection()\n",
    "        \n",
    "        # 加载并插入各类数据\n",
    "        data_files = {\n",
    "            'weibo_data': 'data/weibo_data.json',\n",
    "            'news_results': 'data/news_results.json',\n",
    "            'douban_topics': 'data/douban_topics.json',\n",
    "            'conferences': 'data/conference.json',\n",
    "            'white_papers': 'data/white_paper.json',\n",
    "            'academic_papers': 'data/academic_papers.json'\n",
    "        }\n",
    "        \n",
    "        insert_functions = {\n",
    "            'weibo_data': insert_weibo_data,\n",
    "            'news_results': insert_news_results,\n",
    "            'douban_topics': insert_douban_topics,\n",
    "            'conferences': insert_conferences,\n",
    "            'white_papers': insert_white_papers,\n",
    "            'academic_papers': insert_academic_papers\n",
    "        }\n",
    "        \n",
    "        for table_name, file_path in data_files.items():\n",
    "            print(f\"Processing {table_name}...\")\n",
    "            try:\n",
    "                data = load_json_file(file_path)\n",
    "                insert_functions[table_name](conn, data)\n",
    "                print(f\"Successfully inserted {table_name} data\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {table_name}: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Database connection error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
